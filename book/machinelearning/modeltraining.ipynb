{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6603ef12",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617e059c",
   "metadata": {},
   "source": [
    "## Compute Class Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667a14ad",
   "metadata": {},
   "source": [
    "To handle class imbalance in Machine Learning, there are several methods.\n",
    "<br><br>\n",
    "One of them is adjusting the class weights. \n",
    "<br><br>\n",
    "By giving higher weights to the minority class and lower weights to the majority class, we can regularize the loss function.\n",
    "<br><br>\n",
    "Misclassifying the minority class will result in a higher loss due to the higher weight.\n",
    "<br><br>\n",
    "To incorporate class weights in Tensorflow, use `scikit-learn`'s `compute_class_weight` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfff72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import compute_class_weight\n",
    "\n",
    "X, y = ...\n",
    "\n",
    "# will return an array with weights for each class, e.g. [0.6, 0.6, 1.]\n",
    "class_weights = compute_class_weight(\n",
    "  class_weight=\"balanced\",\n",
    "  classes=np.unique(y),\n",
    "  y=y\n",
    ")\n",
    "\n",
    "# to get a dictionary with {<class>:<weight>}\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "model = tf.keras.Sequential(...)\n",
    "model.compile(...)\n",
    "\n",
    "# using class_weights in the .fit() method\n",
    "model.fit(X, y, class_weight=class_weights, ...)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1981d413",
   "metadata": {},
   "source": [
    "# Free memory in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1342f3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def create_model():\n",
    "  model = tf.keras.Sequential(...)\n",
    "  return model\n",
    "\n",
    "# without clearing session\n",
    "for _ in range(20):\n",
    "  model = create_model()\n",
    "  \n",
    "# with clearing session\n",
    "for _ in range(20):\n",
    "  tf.keras.backend.clear_session()\n",
    "  model = create_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd2797b",
   "metadata": {},
   "source": [
    "# Find dirty labels with cleanlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d918f54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cleanlab\n",
    "\n",
    "import cleanlab\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "cl = cleanlab.classification.CleanLearning(clf)\n",
    "\n",
    "label_issues = cl.find_label_issues(X, y)\n",
    "\n",
    "print(label_issues.query('is_label_issue == True'))\n",
    "\n",
    "    is_label_issue  label_quality  given_label  predicted_label\n",
    "70            True           0.07            1                2\n",
    "77            True           0.01            1                2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d4ed7523",
   "metadata": {},
   "source": [
    "# Find bad labels with doubtlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18d738e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from doubtlab.ensemble import DoubtEnsemble\n",
    "from doubtlab.reason import ProbaReason, WrongPredictionReason\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Define reasons to check\n",
    "reasons = {\n",
    "    'proba': ProbaReason(model=model),\n",
    "    'wrong_pred': WrongPredictionReason(model=model),\n",
    "}\n",
    "\n",
    "# Pass reasons to DoubtLab instance\n",
    "doubt = DoubtEnsemble(**reasons)\n",
    "\n",
    "# Returns DataFrame with reasoning\n",
    "predicates = doubt.get_predicates(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44919184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get notified when your model is finished with training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd32221a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install knockknock\n",
    "from knockknock import email_sender\n",
    "\n",
    "@email_sender(recipient_emails=[\"coolmail@python.com\", \"2coolmail@python.com\"], sender_email=\"anothercoolmail@python.com\")\n",
    "def train_model(model, X, y):\n",
    "    model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01896ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Model Summary in PyTorch with torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a56e2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchinfo\n",
    "\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "\n",
    "class MyModel(torch.nn.Module)\n",
    "  ...\n",
    "  \n",
    "model = MyModel()\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "summary(model, input_size=(BATCH_SIZE, 1, 28, 28))\n",
    "\n",
    "'''\n",
    "==========================================================================================\n",
    "Layer (type:depth-idx)                   Output Shape              Param #\n",
    "==========================================================================================\n",
    "Net                                      [16, 10]                  --\n",
    "├─Sequential: 1-1                        [16, 4, 7, 7]             --\n",
    "│    └─Conv2d: 2-1                       [16, 4, 28, 28]           40\n",
    "│    └─BatchNorm2d: 2-2                  [16, 4, 28, 28]           8\n",
    "│    └─ReLU: 2-3                         [16, 4, 28, 28]           --\n",
    "│    └─MaxPool2d: 2-4                    [16, 4, 14, 14]           --\n",
    "│    └─Conv2d: 2-5                       [16, 4, 14, 14]           148\n",
    "│    └─BatchNorm2d: 2-6                  [16, 4, 14, 14]           8\n",
    "│    └─ReLU: 2-7                         [16, 4, 14, 14]           --\n",
    "│    └─MaxPool2d: 2-8                    [16, 4, 7, 7]             --\n",
    "├─Sequential: 1-2                        [16, 10]                  --\n",
    "│    └─Linear: 2-9                       [16, 10]                  1,970\n",
    "==========================================================================================\n",
    "Total params: 2,174\n",
    "Trainable params: 2,174\n",
    "Non-trainable params: 0\n",
    "Total mult-adds (M): 1.00\n",
    "==========================================================================================\n",
    "Input size (MB): 0.05\n",
    "Forward/backward pass size (MB): 1.00\n",
    "Params size (MB): 0.01\n",
    "Estimated Total Size (MB): 1.06\n",
    "==========================================================================================\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "84b79b5f",
   "metadata": {},
   "source": [
    "# Boost scikit-learns performance with Intel Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8872eb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X, y = make_regression(\n",
    "n_samples=100000, \n",
    "n_features=10, \n",
    "noise=0.5)\n",
    "\n",
    "svr = SVR()\n",
    "\n",
    "svr.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd994b6f",
   "metadata": {},
   "source": [
    "# Aspect-based Seniment Analysis with PyABSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90da9a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyabsa==1.16.27\n",
    "\n",
    "from pyabsa import ATEPCCheckpointManager\n",
    "\n",
    "extractor = ATEPCCheckpointManager.get_aspect_extractor(\n",
    "                  checkpoint=\"multilingual\",\n",
    "                  auto_device=False\n",
    ")\n",
    "                                                        \n",
    "example = [\"Location and food were excellent but stuff was very unfriendly.\"]\n",
    "result = extractor.extract_aspect(inference_source=example, pred_sentiment=True)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8f01a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use XGBoost for Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa3cbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRFRegressor\n",
    "\n",
    "xgbrf = XGBRFRegressor(n_estimators=100)\n",
    "\n",
    "X = np.random.rand(100000, 10)\n",
    "y = np.random.rand(100000)\n",
    "\n",
    "xgbrf.fit(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "54bf0f8d5625db32e314b5bdaf50a44046044c99ae376da8e1ac5bc25f06b01d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
