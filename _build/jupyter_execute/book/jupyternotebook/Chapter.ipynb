{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook Tips and Tricks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify your bottleneck with `line_profiler`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to identify the bottleneck in your Python code?\n",
    "\n",
    "Try the module `line_profiler` for Python.\n",
    "\n",
    "With `line_profiler`, you will get a line-by-line profiling of your functions.\n",
    "\n",
    "So you can exactly see the execution time for every line.\n",
    "\n",
    "Below you can see how to use `line_profiler` within a Jupyter Notebook.\n",
    "\n",
    "- Use the `%load_ext` magic command to load the `line_profiler` extension.\n",
    "- Use the `%lprun` magic command to profile a specific cell or function in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "\n",
    "def my_function(x):\n",
    "    for x in range(1, 10000):\n",
    "      x = x**2\n",
    "      x = x / 400\n",
    "    y = x + x\n",
    "    return y\n",
    "    \n",
    "%lprun -u 1e-3 -f my_function my_function(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Timer unit: 0.001 s\n",
    "\n",
    "Total time: 0.0160793 s\n",
    "File: <ipython-input-18-790da5f104f0>\n",
    "Function: my_function at line 1\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "     1                                           def my_function(x):\n",
    "     2      9999          2.6      0.0     16.3      for x in range(1, 10000):\n",
    "     3      9999          6.1      0.0     37.7        x = x**2\n",
    "     4      9999          7.4      0.0     46.1        x = x / 400\n",
    "     5         1          0.0      0.0      0.0      y = x + x\n",
    "     6         1          0.0      0.0      0.0      return y\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Render Live loss of Deep Learning Models in Jupyter Notebooks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot your live training loss in Jupyter Notebooks with `livelossplot`.\n",
    "\n",
    "`livelossplot` lets you track your model’s training process in real time, only adding one callback. \n",
    "\n",
    "A nice alternative to TensorBoard, if you want to train a small model and visualize its progress quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install livelossplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Activation\n",
    "\n",
    "from livelossplot import PlotLossesKeras\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "Y_train = to_categorical(y_train)\n",
    "Y_test = to_categorical(y_test)\n",
    "X_train = X_train.reshape(-1, 28, 28, 1).astype('float32') / 255.\n",
    "X_test = X_test.reshape(-1, 28, 28, 1).astype('float32') / 255.\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Flatten(input_shape=(28, 28, 1)))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "plotlosses = PlotLossesKeras()\n",
    "\n",
    "model.fit(X_train, Y_train,\n",
    "          epochs=12,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          callbacks=[plotlosses],\n",
    "          verbose=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate LaTeX Expressions from Python Code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `latexify`, you can compile Python source code to a beautiful LaTeX expression.\n",
    "\n",
    "In a quick and easy way!\n",
    "\n",
    "Useful, when you don’t want to write the LaTeX expression by yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install latexify-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import latexify\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@latexify.function\n",
    "def solve(a, b, c):\n",
    "    return (-b + math.sqrt(b**2 - 4*a*c)) / (2*a)\n",
    "\n",
    "print(solve)\n",
    "solve"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Scikit-Learn Pipelines as HTML"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can display an interactive HTML diagram of scikit-learn pipelines. \n",
    "\n",
    "Just set the config to `diagram` (you can still switch back to `text`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import set_config\n",
    "\n",
    "numeric_preprocessor = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputation_mean\", SimpleImputer(missing_values=np.nan, strategy=\"mean\")),\n",
    "        (\"scaling\", RobustScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_preprocessor = Pipeline(\n",
    "    steps=[\n",
    "        (\n",
    "            \"imputation_constant\",\n",
    "            SimpleImputer(fill_value=\"missing\", strategy=\"constant\"),\n",
    "        ),\n",
    "        (\"one_hot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"categorical\", categorical_preprocessor, [\"state\", \"gender\"]),\n",
    "        (\"numerical\", numeric_preprocessor, [\"age\", \"weight\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe = make_pipeline(preprocessor, RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_config(display=\"diagram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoreload your Modules in Jupyter Notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you work on a new Python module and test it in a Jupyter notebook\n",
    "\n",
    "You have to reload the module when you change it.\n",
    "\n",
    "`autoreload` makes sure all modules will be reimported.\n",
    "\n",
    "Just by adding two lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from my_module import my_function1, my_function2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_function1()\n",
    "\n",
    "my_function2()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Code Quality Tools to Jupyter Notebooks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you look for Code quality within Jupyter Notebooks?\n",
    "\n",
    "One limitation of widespread tools like black, flake8 or isort is the incompatibility with notebooks.\n",
    "\n",
    "With `nbqa`, you can effortlessly apply code quality tools to notebooks.\n",
    "\n",
    "See below how we can apply black and isort on notebooks.\n",
    "\n",
    "Say hello to clean(er) notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"nbqa[toolchain]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nbqa black my_notebook.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nbqa isort my_notebook.ipynb --float-to-top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Reuse Juptyer Notebook Templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are a heavy JupyterLab user,\n",
    "\n",
    "do you create a new notebook from scratch every time?\n",
    "\n",
    "With `jupytertemplate`, you don’t need to.\n",
    "\n",
    "`jupytertemplate` lets you create Notebook templates you can reuse every time.\n",
    "\n",
    "Do you have the same structure for every EDA? Create a template and reuse it.\n",
    "\n",
    "No need to create a notebook and structure it manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter labextension install jupyterlab_templates\n",
    "!jupyter server extension enable --py jupyterlab_templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the following to jupyter_notebook_config.py\n",
    "\n",
    "c.JupyterLabTemplates.allowed_extensions = [\"*.ipynb\"]\n",
    "c.JupyterLabTemplates.template_dirs = ['list', 'of', 'template', 'directories']\n",
    "c.JupyterLabTemplates.include_default = True\n",
    "c.JupyterLabTemplates.include_core_paths = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Output Cells Automatically with `nbstripout`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are you tracking outputs of Jupyter Notebooks in Git?\n",
    "\n",
    "Stop that.\n",
    "\n",
    "Output cells in Notebooks can contain large amounts of data, such as the results of computations or visualizations. \n",
    "\n",
    "With `nbstripout`, you can strip them out.\n",
    "\n",
    "It helps you to reduce the size of committed changes and the risk of pushing sensitive data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nbstripout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nbstripout FILE.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring LLMs Into Your Notebook with `jupyter-ai`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bring GenAI into your Jupyter Notebooks with `jupyter-ai`\n",
    "\n",
    "`jupyter-ai` lets you use LLMs from vendors like OpenAI, Huggingface and Anthropic within your Notebook cells.\n",
    "\n",
    "You can just ask for a code snippet and the result will be rendered into your Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env PROVIDER_API_KEY=YOUR_API_KEY_HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jupyter_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext jupyter_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ai chatgpt\n",
    "Provide a hello world function in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modern Alternative to Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forget Jupyter Notebooks.\n",
    "\n",
    "`Marimo` Notebook is the future.\n",
    "\n",
    "`Marimo` Notebooks are a git-friendly, reactive and interactive alternative to Jupyter Notebooks by providing the following features:\n",
    "\n",
    "- Automatically re-running affected cells when changing something\n",
    "- Notebooks are executed in a deterministic order, with no hidden state\n",
    "- Easily deployable\n",
    "- Interactive elements\n",
    "\n",
    "Just give it a try, it's open-source too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install marimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!marimo edit"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}