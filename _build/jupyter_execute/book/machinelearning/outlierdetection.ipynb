{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Detection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembling for Outlier Detection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to its unsupervised nature, outlier detection methods often suffer from model instability.\n",
    "\n",
    "So, why not combine various models?\n",
    "\n",
    "Try `PyOD`!\n",
    "\n",
    "`PyOD` is an easy-to-use library for outlier detection.\n",
    "\n",
    "It includes more than 30 algorithms like density-based methods or ensembles.\n",
    "\n",
    "`PyOD` also supports combining multiple methods like\n",
    "\n",
    "- Average of scores\n",
    "- Maximization of scores\n",
    "- Average of Maximum of scores\n",
    "- Maximum of Average of scores\n",
    "- Majority Vote\n",
    "\n",
    "To combine multiple models in Python, consider the example below.\n",
    "\n",
    "- We define 3 outlier detectors.\n",
    "- We calculate the labels for every detector (0=inliner, 1=outlier).\n",
    "- We use `majority_vote()` method to calculate the highest-voted label for each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyod.models.combination import majority_vote\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.abod import ABOD\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.utils.data import generate_data\n",
    "\n",
    "X, _= generate_data(train_only=True)\n",
    "\n",
    "models = [KNN(), ABOD(), IForest()]\n",
    "n_models = len(models)\n",
    "\n",
    "labels = np.zeros([X.shape[0], n_models])\n",
    "\n",
    "for i in range(n_models):\n",
    "    model = models[i]\n",
    "\n",
    "    model.fit(X)\n",
    "\n",
    "    labels[:, i] = model.labels_\n",
    "    \n",
    "majority_vote(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robust Outlier Detection with `puncc`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outlier Detection is notoriously hard.\n",
    "\n",
    "But it doesn't have to.\n",
    "\n",
    "`puncc` offers outlier detection, powered by Conformal Prediction, where the detection threshold will be calibrated.\n",
    "\n",
    "So, false alarms are reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install puncc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from deel.puncc.anomaly_detection import SplitCAD\n",
    "from deel.puncc.api.prediction import BasePredictor\n",
    "\n",
    "# We need to redefine the predict to output the nonconformity scores.\n",
    "class ADPredictor(BasePredictor):\n",
    "    def predict(self, X):\n",
    "        return -self.model.score_samples(X)\n",
    "\n",
    "# Wrap Isolation Forest in a predictor\n",
    "if_predictor = ADPredictor(IsolationForest())\n",
    "\n",
    "# Instantiate CAD on top of IF predictor\n",
    "if_cad = SplitCAD(if_predictor, train=True)\n",
    "\n",
    "\n",
    "if_cad.fit(z=dataset, fit_ratio=0.7)\n",
    "\n",
    "# Maximum false detection rate\n",
    "alpha = 0.01\n",
    "\n",
    "results = if_cad.predict(new_data, alpha=alpha)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}